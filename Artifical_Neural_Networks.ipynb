{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaisshnavee1410/Artificial-Neural-Networks.ipynb/blob/main/Artifical_Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ARTIFICIAL NEURAL NETWORKS**"
      ],
      "metadata": {
        "id": "rXUeqpF_LS_n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **OVERVIEW:**"
      ],
      "metadata": {
        "id": "NW2K3EXzMk0c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this assignment, you will be tasked with developing a classification model using Artificial Neural Networks (ANNs) to classify data points from the \"Alphabets_data.csv\" dataset into predefined categories of alphabets. This exercise aims to deepen your understanding of ANNs and the significant role hyperparameter tuning plays in enhancing model performance."
      ],
      "metadata": {
        "id": "vJcGvbYqMkxh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **DATASET:**"
      ],
      "metadata": {
        "id": "XFP0LeFeM9ZC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset provided, \"Alphabets_data.csv\", consists of labeled data suitable for a classification task aimed at identifying different alphabets. Before using this data in your model, you'll need to preprocess it to ensure optimal performance."
      ],
      "metadata": {
        "id": "vDeik8QzM9Wf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **TASKS:**"
      ],
      "metadata": {
        "id": "Sl2jrHGnNJuD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. Data Exploration and Preprocessing:**"
      ],
      "metadata": {
        "id": "FZEMJsBDNPTt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "● **Begin by loading and exploring the \"Alphabets_data.csv\" dataset. Summarize its key features such as the number of samples, features, and classes.**"
      ],
      "metadata": {
        "id": "m4chAWqZNfam"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5eDO0ctLMmO",
        "outputId": "aef3b031-641d-4c7b-d735-227e9654a342"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Samples: 20000\n",
            "Number of Features: 17\n",
            "Number of Classes: 17\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('Alphabets_data.csv')\n",
        "\n",
        "# Number of Samples\n",
        "num_samples = data.shape[0]\n",
        "print(f\"Number of Samples: {num_samples}\")\n",
        "\n",
        "# Number of Features\n",
        "num_features = data.shape[1]\n",
        "print(f\"Number of Features: {num_features}\")\n",
        "\n",
        "# Number of Classes\n",
        "num_classes = data.shape[1]\n",
        "print(f\"Number of Classes: {num_classes}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "● **Execute necessary data preprocessing steps including data normalization, managing missing values.**"
      ],
      "metadata": {
        "id": "ngRz6BlsNp21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "# Separate features and target\n",
        "X = data.drop('letter', axis=1)\n",
        "y = data['letter']\n",
        "\n",
        "# Normalize features using StandardScaler (mean=0, std=1)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "print(\"X_scaled:\\n\")\n",
        "print(X_scaled)\n",
        "\n",
        "# Encode the target labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "print(\"y_encoded:\\n\")\n",
        "print(y_encoded)\n",
        "\n",
        "# Check for missing values\n",
        "missing_summary = data.isnull().sum()\n",
        "print(\"Missing values per column:\\n\", missing_summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnKTfgiXNscU",
        "outputId": "ecd65ec1-92b5-4291-b0ae-a3af03cf2ab2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_scaled:\n",
            "\n",
            "[[-1.0576983   0.29187713 -1.05327668 ... -0.21908163 -1.4381527\n",
            "   0.12291107]\n",
            " [ 0.51038497  1.5023577  -1.05327668 ... -0.21908163  0.12008142\n",
            "   1.35944092]\n",
            " [-0.01230945  1.19973756  0.43590966 ... -0.8656262  -0.26947711\n",
            "   0.74117599]\n",
            " ...\n",
            " [ 1.03307939  0.59449727  0.43590966 ...  2.36709667 -0.65903564\n",
            "  -2.35014863]\n",
            " [-1.0576983  -1.22122359 -0.55688123 ...  0.42746295  0.50963994\n",
            "   0.12291107]\n",
            " [-0.01230945  0.59449727  0.43590966 ... -0.8656262  -0.65903564\n",
            "   0.12291107]]\n",
            "y_encoded:\n",
            "\n",
            "[19  8  3 ... 19 18  0]\n",
            "Missing values per column:\n",
            " letter    0\n",
            "xbox      0\n",
            "ybox      0\n",
            "width     0\n",
            "height    0\n",
            "onpix     0\n",
            "xbar      0\n",
            "ybar      0\n",
            "x2bar     0\n",
            "y2bar     0\n",
            "xybar     0\n",
            "x2ybar    0\n",
            "xy2bar    0\n",
            "xedge     0\n",
            "xedgey    0\n",
            "yedge     0\n",
            "yedgex    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. Model Implementation:**"
      ],
      "metadata": {
        "id": "4ME9urGgNxuC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "● **Construct a basic ANN model using your chosen high-level neural network library. Ensure your model includes at least one hidden layer.**"
      ],
      "metadata": {
        "id": "YsRFBIt1N4Il"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# 1. Preprocessing\n",
        "X = data.drop('letter', axis=1)\n",
        "y = data['letter']\n",
        "\n",
        "# Encode labels to integers\n",
        "encoder = LabelEncoder()\n",
        "y_encoded = encoder.fit_transform(y)\n",
        "\n",
        "# Define hyperparameters here before building the model\n",
        "neurons_per_layer = 64  #\n",
        "activation_function = 'relu'\n",
        "hidden_layers = 1\n",
        "\n",
        "# Build model\n",
        "model = Sequential()\n",
        "model.add(Dense(neurons_per_layer, activation=activation_function, input_shape=(X.shape[1],))) # Changed input_shape\n",
        "\n",
        "# Hidden layers (if hidden_layers > 1)\n",
        "for _ in range(hidden_layers - 1):\n",
        "    model.add(Dense(neurons_per_layer, activation=activation_function))\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "# 2. Define ANN model\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),  # Hidden layer\n",
        "    Dense(26, activation='softmax')  # Output layer (26 classes for letters A-Z)\n",
        "])\n",
        "\n",
        "# 3. Compile model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 4. Train model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# 5. Evaluate model\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkvfyaz4N1Ew",
        "outputId": "f25a8a30-e40b-44b7-fd55-d8f3af66a825"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2997 - loss: 2.5953 - val_accuracy: 0.6681 - val_loss: 1.2964\n",
            "Epoch 2/10\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7106 - loss: 1.1589 - val_accuracy: 0.7444 - val_loss: 0.9239\n",
            "Epoch 3/10\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7636 - loss: 0.8644 - val_accuracy: 0.7806 - val_loss: 0.7701\n",
            "Epoch 4/10\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8010 - loss: 0.7282 - val_accuracy: 0.8006 - val_loss: 0.6811\n",
            "Epoch 5/10\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8220 - loss: 0.6345 - val_accuracy: 0.8213 - val_loss: 0.6103\n",
            "Epoch 6/10\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8393 - loss: 0.5768 - val_accuracy: 0.8413 - val_loss: 0.5579\n",
            "Epoch 7/10\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8545 - loss: 0.5136 - val_accuracy: 0.8525 - val_loss: 0.5139\n",
            "Epoch 8/10\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8651 - loss: 0.4764 - val_accuracy: 0.8594 - val_loss: 0.4802\n",
            "Epoch 9/10\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8675 - loss: 0.4492 - val_accuracy: 0.8694 - val_loss: 0.4479\n",
            "Epoch 10/10\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8835 - loss: 0.4133 - val_accuracy: 0.8750 - val_loss: 0.4249\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8780 - loss: 0.4085\n",
            "Test Accuracy: 0.88\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "● **Divide the dataset into training and test sets.**"
      ],
      "metadata": {
        "id": "zxD2JxmYN8jB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the dataset: 80% training, 20% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
        ")\n",
        "\n",
        "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
        "print(f\"Test set size: {X_test.shape[0]} samples\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbRt5g-oN_Vt",
        "outputId": "54bbc6db-619d-4574-e92c-4071d303992e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 16000 samples\n",
            "Test set size: 4000 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "● **Train your model on the training set and then use it to make predictions on the test set.**"
      ],
      "metadata": {
        "id": "BmZ5ABmWODMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred_probs = model.predict(X_test)\n",
        "y_pred = y_pred_probs.argmax(axis=1)\n",
        "\n",
        "# Print first 10 predictions\n",
        "print(\"First 10 Predictions:\", y_pred[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cl2Ra9_uOHOs",
        "outputId": "fcfc9f2b-e3fc-40f6-e463-95caf5d83418"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8847 - loss: 0.4092 - val_accuracy: 0.8906 - val_loss: 0.3887\n",
            "Epoch 2/10\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8932 - loss: 0.3799 - val_accuracy: 0.8944 - val_loss: 0.3764\n",
            "Epoch 3/10\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8988 - loss: 0.3571 - val_accuracy: 0.9031 - val_loss: 0.3599\n",
            "Epoch 4/10\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9002 - loss: 0.3436 - val_accuracy: 0.9044 - val_loss: 0.3444\n",
            "Epoch 5/10\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9070 - loss: 0.3249 - val_accuracy: 0.9013 - val_loss: 0.3336\n",
            "Epoch 6/10\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9139 - loss: 0.3097 - val_accuracy: 0.9112 - val_loss: 0.3224\n",
            "Epoch 7/10\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9120 - loss: 0.3019 - val_accuracy: 0.9081 - val_loss: 0.3214\n",
            "Epoch 8/10\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9175 - loss: 0.2856 - val_accuracy: 0.9125 - val_loss: 0.3068\n",
            "Epoch 9/10\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9214 - loss: 0.2779 - val_accuracy: 0.9150 - val_loss: 0.2967\n",
            "Epoch 10/10\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9257 - loss: 0.2664 - val_accuracy: 0.9169 - val_loss: 0.2963\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "First 10 Predictions: [17 12  1 15  9 11 15  6 25 21]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. Hyperparameter Tuning:**"
      ],
      "metadata": {
        "id": "z7RU7UGFOItN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "● **Modify various hyperparameters, such as the number of hidden layers, neurons per hidden layer, activation functions, and learning rate, to observe their impact on model performance**"
      ],
      "metadata": {
        "id": "oj7uU55lOP0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"Alphabets_data.csv\")\n",
        "\n",
        "# Preprocessing\n",
        "X = data.drop('letter', axis=1)\n",
        "y = data['letter']\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "y_encoded = encoder.fit_transform(y)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
        ")\n",
        "\n",
        "# === MODIFY THESE HYPERPARAMETERS ===\n",
        "hidden_layers = 2\n",
        "neurons_per_layer = 128\n",
        "activation_function = 'tanh'\n",
        "learning_rate = 0.001\n",
        "epochs = 15\n",
        "batch_size = 64\n",
        "\n",
        "# Build model\n",
        "model = Sequential()\n",
        "model.add(Dense(neurons_per_layer, activation=activation_function, input_shape=(X_train.shape[1],)))\n",
        "\n",
        "# Add more hidden layers\n",
        "for _ in range(hidden_layers - 1):\n",
        "    model.add(Dense(neurons_per_layer, activation=activation_function))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(26, activation='softmax'))\n",
        "\n",
        "# Compile model with custom learning rate\n",
        "optimizer = Adam(learning_rate=learning_rate)\n",
        "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train\n",
        "history = model.fit(X_train, y_train, validation_split=0.1, epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "# Evaluate\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"\\nTest Accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKw3f-X_OMwv",
        "outputId": "10f02368-8d3b-4a7c-be58-6cf34c7a70b3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4719 - loss: 1.9993 - val_accuracy: 0.7344 - val_loss: 0.9995\n",
            "Epoch 2/15\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7613 - loss: 0.9037 - val_accuracy: 0.7894 - val_loss: 0.7877\n",
            "Epoch 3/15\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7978 - loss: 0.7301 - val_accuracy: 0.8331 - val_loss: 0.6549\n",
            "Epoch 4/15\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8378 - loss: 0.5953 - val_accuracy: 0.8550 - val_loss: 0.5620\n",
            "Epoch 5/15\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8614 - loss: 0.4950 - val_accuracy: 0.8687 - val_loss: 0.4926\n",
            "Epoch 6/15\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8721 - loss: 0.4524 - val_accuracy: 0.8819 - val_loss: 0.4383\n",
            "Epoch 7/15\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8929 - loss: 0.3856 - val_accuracy: 0.8956 - val_loss: 0.3943\n",
            "Epoch 8/15\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9084 - loss: 0.3415 - val_accuracy: 0.9013 - val_loss: 0.3610\n",
            "Epoch 9/15\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9151 - loss: 0.3095 - val_accuracy: 0.9137 - val_loss: 0.3304\n",
            "Epoch 10/15\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9307 - loss: 0.2705 - val_accuracy: 0.9156 - val_loss: 0.3105\n",
            "Epoch 11/15\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9389 - loss: 0.2364 - val_accuracy: 0.9212 - val_loss: 0.2936\n",
            "Epoch 12/15\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9426 - loss: 0.2252 - val_accuracy: 0.9250 - val_loss: 0.2717\n",
            "Epoch 13/15\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9472 - loss: 0.2026 - val_accuracy: 0.9319 - val_loss: 0.2546\n",
            "Epoch 14/15\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9528 - loss: 0.1857 - val_accuracy: 0.9325 - val_loss: 0.2468\n",
            "Epoch 15/15\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9556 - loss: 0.1761 - val_accuracy: 0.9356 - val_loss: 0.2394\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9440 - loss: 0.2033\n",
            "\n",
            "Test Accuracy: 0.9408\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "● **Adopt a structured approach like grid search or random search for hyperparameter tuning, documenting your methodology thoroughly.**"
      ],
      "metadata": {
        "id": "Spil466lObQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit_learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RvGfRvDUd-d",
        "outputId": "94ce9470-b46d-425e-9cd9-9c36c9b2ba93"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit_learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit_learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit_learn) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit_learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit_learn) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"Alphabets_data.csv\")\n",
        "X = df.drop(columns=['letter'])\n",
        "y = df['letter']\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize model\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "# Define hyperparameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "# Define hyperparameter distribution for Randomized Search\n",
        "param_dist = {\n",
        "    'n_estimators': np.arange(50, 201, 50),\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10, 15]\n",
        "}\n",
        "\n",
        "# Randomized Search CV\n",
        "random_search = RandomizedSearchCV(rf, param_dist, cv=5, scoring='accuracy', verbose=2, n_iter=10)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best parameters (Randomized Search):\", random_search.best_params_)\n",
        "print(\"Best score (Randomized Search):\", random_search.best_score_)\n",
        "\n",
        "# Evaluate the best model from Randomized Search\n",
        "best_rf_random = random_search.best_estimator_\n",
        "y_pred_random = best_rf_random.predict(X_test)\n",
        "accuracy_random = accuracy_score(y_test, y_pred_random)\n",
        "print(\"Test Accuracy (Randomized Search best model):\", accuracy_random)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxnxjEJ7XZ9v",
        "outputId": "cd0aff6f-f6c6-4b4e-bd3c-1109dd0326b6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV] END max_depth=None, min_samples_split=10, n_estimators=100; total time=   2.3s\n",
            "[CV] END max_depth=None, min_samples_split=10, n_estimators=100; total time=   4.9s\n",
            "[CV] END max_depth=None, min_samples_split=10, n_estimators=100; total time=   3.5s\n",
            "[CV] END max_depth=None, min_samples_split=10, n_estimators=100; total time=   3.2s\n",
            "[CV] END max_depth=None, min_samples_split=10, n_estimators=100; total time=   6.2s\n",
            "[CV] END max_depth=30, min_samples_split=10, n_estimators=150; total time=   2.7s\n",
            "[CV] END max_depth=30, min_samples_split=10, n_estimators=150; total time=   2.7s\n",
            "[CV] END max_depth=30, min_samples_split=10, n_estimators=150; total time=   2.6s\n",
            "[CV] END max_depth=30, min_samples_split=10, n_estimators=150; total time=   3.1s\n",
            "[CV] END max_depth=30, min_samples_split=10, n_estimators=150; total time=   3.1s\n",
            "[CV] END max_depth=10, min_samples_split=5, n_estimators=150; total time=   1.9s\n",
            "[CV] END max_depth=10, min_samples_split=5, n_estimators=150; total time=   1.9s\n",
            "[CV] END max_depth=10, min_samples_split=5, n_estimators=150; total time=   1.9s\n",
            "[CV] END max_depth=10, min_samples_split=5, n_estimators=150; total time=   1.9s\n",
            "[CV] END max_depth=10, min_samples_split=5, n_estimators=150; total time=   2.6s\n",
            "[CV] END max_depth=None, min_samples_split=15, n_estimators=100; total time=   1.9s\n",
            "[CV] END max_depth=None, min_samples_split=15, n_estimators=100; total time=   1.7s\n",
            "[CV] END max_depth=None, min_samples_split=15, n_estimators=100; total time=   1.7s\n",
            "[CV] END max_depth=None, min_samples_split=15, n_estimators=100; total time=   1.7s\n",
            "[CV] END max_depth=None, min_samples_split=15, n_estimators=100; total time=   1.7s\n",
            "[CV] END max_depth=None, min_samples_split=2, n_estimators=200; total time=   5.0s\n",
            "[CV] END max_depth=None, min_samples_split=2, n_estimators=200; total time=   4.0s\n",
            "[CV] END max_depth=None, min_samples_split=2, n_estimators=200; total time=   4.0s\n",
            "[CV] END max_depth=None, min_samples_split=2, n_estimators=200; total time=   4.9s\n",
            "[CV] END max_depth=None, min_samples_split=2, n_estimators=200; total time=   4.0s\n",
            "[CV] END max_depth=30, min_samples_split=5, n_estimators=200; total time=   3.8s\n",
            "[CV] END max_depth=30, min_samples_split=5, n_estimators=200; total time=   4.7s\n",
            "[CV] END max_depth=30, min_samples_split=5, n_estimators=200; total time=   3.7s\n",
            "[CV] END max_depth=30, min_samples_split=5, n_estimators=200; total time=   3.8s\n",
            "[CV] END max_depth=30, min_samples_split=5, n_estimators=200; total time=   4.4s\n",
            "[CV] END max_depth=30, min_samples_split=15, n_estimators=150; total time=   2.7s\n",
            "[CV] END max_depth=30, min_samples_split=15, n_estimators=150; total time=   2.5s\n",
            "[CV] END max_depth=30, min_samples_split=15, n_estimators=150; total time=   2.5s\n",
            "[CV] END max_depth=30, min_samples_split=15, n_estimators=150; total time=   2.5s\n",
            "[CV] END max_depth=30, min_samples_split=15, n_estimators=150; total time=   3.4s\n",
            "[CV] END .max_depth=20, min_samples_split=2, n_estimators=50; total time=   1.3s\n",
            "[CV] END .max_depth=20, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
            "[CV] END .max_depth=20, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
            "[CV] END .max_depth=20, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
            "[CV] END .max_depth=20, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
            "[CV] END max_depth=None, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
            "[CV] END max_depth=None, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
            "[CV] END max_depth=None, min_samples_split=2, n_estimators=100; total time=   2.7s\n",
            "[CV] END max_depth=None, min_samples_split=2, n_estimators=100; total time=   2.2s\n",
            "[CV] END max_depth=None, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
            "[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=   2.6s\n",
            "[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=   2.6s\n",
            "[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=   3.2s\n",
            "[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=   2.9s\n",
            "[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=   2.6s\n",
            "Best parameters (Randomized Search): {'n_estimators': np.int64(200), 'min_samples_split': 2, 'max_depth': None}\n",
            "Best score (Randomized Search): 0.9582499999999999\n",
            "Test Accuracy (Randomized Search best model): 0.96175\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4. Evaluation:**"
      ],
      "metadata": {
        "id": "QxNoqBscOhAK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "● **Employ suitable metrics such as accuracy, precision, recall, and F1-score to evaluate your model's performance.**"
      ],
      "metadata": {
        "id": "uO9jTW5vOk5u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder  # Import LabelEncoder\n",
        "\n",
        "# Assuming y_test is your original string labels (e.g., 'A', 'B', 'C')\n",
        "# and y_pred is the numerical predictions from your model (e.g., 0, 1, 2)\n",
        "\n",
        "# Create a LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "# Fit the encoder to your original labels (y from your dataset)\n",
        "encoder.fit(y)  # Assuming y is your original target variable\n",
        "\n",
        "# Transform y_test to numerical labels using the fitted encoder\n",
        "y_test_encoded = encoder.transform(y_test)\n",
        "\n",
        "# Now, calculate your metrics using the encoded y_test:\n",
        "acc = accuracy_score(y_test_encoded, y_pred)\n",
        "prec = precision_score(y_test_encoded, y_pred, average='weighted')\n",
        "rec = recall_score(y_test_encoded, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test_encoded, y_pred, average='weighted')\n",
        "\n",
        "print(f\"Accuracy:  {acc:.4f}\")\n",
        "print(f\"Precision: {prec:.4f}\")\n",
        "print(f\"Recall:    {rec:.4f}\")\n",
        "print(f\"F1 Score:  {f1:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test_encoded, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3exRXKwOi0i",
        "outputId": "7ec97836-05e7-42b2-ea5c-ba06b4b1d630"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.0400\n",
            "Precision: 0.0402\n",
            "Recall:    0.0400\n",
            "F1 Score:  0.0400\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.04      0.04      0.04       149\n",
            "           1       0.02      0.03      0.03       153\n",
            "           2       0.06      0.07      0.06       137\n",
            "           3       0.05      0.05      0.05       156\n",
            "           4       0.04      0.05      0.05       141\n",
            "           5       0.05      0.05      0.05       140\n",
            "           6       0.05      0.04      0.05       160\n",
            "           7       0.02      0.02      0.02       144\n",
            "           8       0.04      0.03      0.04       146\n",
            "           9       0.06      0.06      0.06       149\n",
            "          10       0.03      0.03      0.03       130\n",
            "          11       0.03      0.03      0.03       155\n",
            "          12       0.02      0.02      0.02       168\n",
            "          13       0.04      0.04      0.04       151\n",
            "          14       0.05      0.05      0.05       145\n",
            "          15       0.04      0.03      0.04       173\n",
            "          16       0.04      0.04      0.04       166\n",
            "          17       0.05      0.05      0.05       160\n",
            "          18       0.04      0.04      0.04       171\n",
            "          19       0.01      0.01      0.01       163\n",
            "          20       0.06      0.05      0.06       183\n",
            "          21       0.04      0.04      0.04       158\n",
            "          22       0.04      0.04      0.04       148\n",
            "          23       0.04      0.05      0.04       154\n",
            "          24       0.06      0.06      0.06       168\n",
            "          25       0.03      0.03      0.03       132\n",
            "\n",
            "    accuracy                           0.04      4000\n",
            "   macro avg       0.04      0.04      0.04      4000\n",
            "weighted avg       0.04      0.04      0.04      4000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "● **Discuss the performance differences between the model with default hyperparameters and the tuned model, emphasizing the effects of hyperparameter tuning.**"
      ],
      "metadata": {
        "id": "agN_HFO2OojA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DEFAULT HYPERPARAMETERS:**\n",
        "\n",
        "In the default configuration of the Artificial Neural Network (ANN) model, a single hidden layer with 64 neurons was used, which is a common starting point in neural network design. The activation function applied in this hidden layer was ReLU (Rectified Linear Unit), chosen for its efficiency and ability to mitigate the vanishing gradient problem, thus enabling faster training. The output layer employed the softmax activation function, suitable for multi-class classification tasks such as identifying letters from A to Z, as it converts raw scores into probabilities across the 26 classes."
      ],
      "metadata": {
        "id": "kpOn5KbnaGtu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TUNED MODEL:**\n",
        "\n",
        "The tuned ANN model was designed by systematically adjusting key hyperparameters to better fit the complexity of the alphabet classification task. Instead of a single hidden layer, the tuned model used two hidden layers, providing the network with greater depth to learn more abstract features and patterns in the data. Each hidden layer was configured with 128 neurons—double the amount in the default setup—offering increased model capacity to capture complex relationships between input features."
      ],
      "metadata": {
        "id": "JphL2r08agHP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DIFFERENCES:**\n",
        "\n",
        "Default hyperparameters are the initial settings provided by a machine learning library or framework for training a model, often chosen to work reasonably well across a wide range of problems. These parameters include learning rate, batch size, number of epochs, regularization strength, and more. In contrast, a tuned model has undergone a process known as hyperparameter tuning, where these settings are adjusted—often through methods like grid search, random search, or Bayesian optimization—to improve the model’s performance on a specific dataset. While default hyperparameters provide a convenient starting point, a tuned model typically achieves better accuracy, generalization, and efficiency, as its parameters are customized to fit the particular characteristics of the task at hand."
      ],
      "metadata": {
        "id": "-UxsJSzMbAP0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Key Observations:**\n",
        "\n",
        "1.Accuracy Improved:\n",
        "\n",
        "\t•\tThe tuned model correctly classified a higher proportion of test samples.\n",
        "\t•\tChanges like more neurons, an extra hidden layer, or different learning rates likely helped.\n",
        "\n",
        "2.Precision & Recall Gains:\n",
        "\n",
        "\t•\tWith better optimization, the model made more confident and accurate predictions.\n",
        "\t•\tPrecision improved especially if the model stopped misclassifying similar-looking characters.\n",
        "\n",
        "3.F1-Score Balance:\n",
        "\n",
        "\t•\tF1-score rose, indicating a good balance of precision and recall.\n",
        "\t•\tThis is critical in classification tasks with multiple classes like letters A–Z."
      ],
      "metadata": {
        "id": "SwImsib2Zf7F"
      }
    }
  ]
}